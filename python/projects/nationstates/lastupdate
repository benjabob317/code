#!/usr/bin/env python3
import urllib.request
from urllib.error import HTTPError
import math
import time

site = urllib.request.urlopen("https://www.nationstates.net/region=doll_guldur")
html = str(site.read())
nation_count = int(html.split('<a href="region=doll_guldur/page=list_nations">')[1].split(' nations')[0]) #amount of nations in the region

raw_nations = []
for page in range(0, math.ceil(nation_count/10)):
    link = "https://www.nationstates.net/page=list_nations/region=doll_guldur/censusid=80?start=" + str(page*10)
    site = urllib.request.urlopen(link)
    html = str(site.read())
    for x in html.split('nation='):
        raw_nations.append(x.split('"')[0]) #adds nation links to the list
    print("Page " + str(page+1) + " of " + str(math.ceil(nation_count/10)) + " scanned")
print("All nation pages scanned\n")

for x in raw_nations:
    if "censusid" in x:
        raw_nations.remove(x) #removes duplicates involving census id
for x in raw_nations:
    if "<!DOCTYPE" in x:
        raw_nations.remove(x) #removes non-nations caused by doctype html

unique_nations = []
for x in raw_nations:
    if x not in unique_nations:
        unique_nations.append(x) #removes duplicates of nations, highly unlikely but just in case

#This section of the program gets all the update times available for each nation. This process will take a long time.
update_times = []
for x in range(0, len(unique_nations)):
    nation = "https://www.nationstates.net/cgi-bin/rss.cgi?nation=" + unique_nations[x]
    try:
        nationsite = urllib.request.urlopen(nation)
    except HTTPError:
        print(unique_nations[x] + ' - 404 nation not found')
    else:
        nationhtml = str(nationsite.read())
        if len(nationhtml.split('influence in Doll Guldur')) > 1:
            for y in range(1, len(nationhtml.split('influence in Doll Guldur'))):
                update_times.append(nationhtml.split('influence in Doll Guldur')[y].split('<pubDate>')[1].split('</pubDate>')[0]) #update time as a string
        print('Nation ' + str(x+1) + ' out of ' + str(nation_count) + ' - success')

months = {'Jan': 31, 'Feb': 28, 'Mar': 31, 'Apr': 30, 'May': 31, 'Jun': 30, 'Jul': 31, 'Aug': 31, 'Sep': 30, 'Oct': 31, 'Nov': 30, 'Dec': 31} #used to sort update times
def days_since_2000(year, month, day):
    days = (year-2000)*365
    days += math.ceil((year-2000)/4) #leap years
update_times.sort(key=lambda x: 0 - (365*int(x.split()[3]) + 35*months.index(x.split()[2]) + int(x.split()[1]))) #Sorts the update times based on year, month, and 
print(update_times)